{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b87c9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, metrics\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalAveragePooling1D, Dense, Dropout, BatchNormalization, Concatenate, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac525b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../Data/freesolv.csv')\n",
    "data_clean = data.dropna(subset=['smiles'])\n",
    "smiles = data_clean['smiles']\n",
    "labels = data_clean['freesolv'].astype(float).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2746663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smiles_dict = {\n",
    "    \"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2,\n",
    "    \"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6,\n",
    "    \"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43,\n",
    "    \"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13,\n",
    "    \"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50,\n",
    "}\n",
    "MAX_SMI_LEN = 100\n",
    "NUM_CHARS = max(smiles_dict.values()) + 1\n",
    "XD = np.zeros((len(smiles), MAX_SMI_LEN, NUM_CHARS))\n",
    "for i, smi in enumerate(smiles):\n",
    "    for j, ch in enumerate(smi[:MAX_SMI_LEN]):\n",
    "        XD[i, j, smiles_dict.get(ch, 0)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "309d45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XDinput = Input(shape=(MAX_SMI_LEN, NUM_CHARS), name='XDinput')\n",
    "encode_smiles = Conv1D(filters=64, kernel_size=2, activation='relu')(XDinput)\n",
    "encode_smiles = Conv1D(filters=64, kernel_size=4, activation='relu')(encode_smiles)\n",
    "encode_smiles = Conv1D(filters=128, kernel_size=4, activation='relu')(encode_smiles)\n",
    "model_feature = keras.Model(inputs=XDinput, outputs=encode_smiles, name='model_feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc635405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TopkRouting(layers.Layer):\n",
    "    def __init__(self, qk_dim, topk=16, qk_scale=None):\n",
    "        super().__init__()\n",
    "        self.topk = topk\n",
    "        self.qk_dim = qk_dim\n",
    "        self.scale = qk_scale if qk_scale is not None else qk_dim**-0.5\n",
    "        self.to_q = layers.Dense(qk_dim)\n",
    "        self.to_k = layers.Dense(qk_dim)\n",
    "        self.to_v = layers.Dense(qk_dim)\n",
    "    def call(self, x):\n",
    "        q = self.to_q(x)\n",
    "        k = self.to_k(x)\n",
    "        v = self.to_v(x)\n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "        topk = tf.nn.top_k(attn, k=self.topk).indices\n",
    "        gather = tf.gather(v, topk, batch_dims=1)\n",
    "        return tf.reduce_mean(gather, axis=2)\n",
    "\n",
    "class Block(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, topk=16, mlp_ratio=3):\n",
    "        super().__init__()\n",
    "        self.attn = TopkRouting(dim, topk)\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(dim*mlp_ratio, activation='relu'),\n",
    "            layers.Dense(dim)\n",
    "        ])\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "    def call(self, x):\n",
    "        h = self.attn(x)\n",
    "        x = self.norm1(x + h)\n",
    "        h2 = self.mlp(x)\n",
    "        return self.norm2(x + h2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "105e496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"interactionModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"interactionModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ model_feature       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,936</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,864</span> │ model_feature[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,864</span> │ model_feature[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m51\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ model_feature       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m55,936\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_6 (\u001b[38;5;33mBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m148,864\u001b[0m │ model_feature[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_7 (\u001b[38;5;33mBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m148,864\u001b[0m │ model_feature[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ block_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ block_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m2\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_5 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,664</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353,664\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,664</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m353,664\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dim = 128\n",
    "transformer_block1 = Block(dim)\n",
    "transformer_block2 = Block(dim)\n",
    "\n",
    "input_inter = Input(shape=(MAX_SMI_LEN, NUM_CHARS))\n",
    "features = model_feature(input_inter)\n",
    "trans1 = transformer_block1(features)\n",
    "trans1 = Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(trans1)\n",
    "trans2 = transformer_block2(features)\n",
    "trans2 = Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(trans2)\n",
    "combined = Concatenate(axis=-1)([trans1, trans2])\n",
    "pooled = GlobalAveragePooling1D()(combined)\n",
    "difference = Lambda(lambda x: tf.expand_dims(x[:,0]-x[:,1], axis=-1))(pooled)\n",
    "interactionModel = keras.Model(inputs=input_inter, outputs=difference, name='interactionModel')\n",
    "interactionModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b4a3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XD_np = np.array(XD)\n",
    "labels_np = labels\n",
    "index = np.where(~np.isnan(labels_np))\n",
    "XD_np = XD_np[index]\n",
    "labels_np = labels_np[index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XD_np, labels_np, test_size=0.2, random_state=9)\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = scaler_y.transform(y_test.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34682f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Scott.Coffin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:855: UserWarning: Gradients do not exist for variables ['block_6/topk_routing_6/dense_30/kernel', 'block_6/topk_routing_6/dense_30/bias', 'block_6/topk_routing_6/dense_31/kernel', 'block_6/topk_routing_6/dense_31/bias', 'block_7/topk_routing_7/dense_35/kernel', 'block_7/topk_routing_7/dense_35/bias', 'block_7/topk_routing_7/dense_36/kernel', 'block_7/topk_routing_7/dense_36/bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 1.3372 - mae: 0.8220 - mse: 1.3372 - r2_score: -3.2521\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 601ms/step - loss: 1.4228 - mae: 0.8325 - mse: 1.4228 - r2_score: -3.2521\n",
      "Epoch 2/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 3.8799 - mae: 1.3821 - mse: 3.8799 - r2_score: -1.6657\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - loss: 3.9485 - mae: 1.4002 - mse: 3.9485 - r2_score: -1.6657\n",
      "Epoch 3/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: 2.4478 - mae: 1.2718 - mse: 2.4478 - r2_score: -0.4966\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - loss: 2.4372 - mae: 1.2631 - mse: 2.4372 - r2_score: -0.4966\n",
      "Epoch 4/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 1.3812 - mae: 0.9130 - mse: 1.3812 - r2_score: -0.2041\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step - loss: 1.4038 - mae: 0.9166 - mse: 1.4038 - r2_score: -0.2041\n",
      "Epoch 5/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 1.2182 - mae: 0.8381 - mse: 1.2182 - r2_score: -0.1126\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - loss: 1.2022 - mae: 0.8298 - mse: 1.2022 - r2_score: -0.1126\n",
      "Epoch 6/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 1.1341 - mae: 0.8037 - mse: 1.1341 - r2_score: -0.0764\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - loss: 1.1196 - mae: 0.7971 - mse: 1.1196 - r2_score: -0.0764\n",
      "Epoch 7/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 1.1069 - mae: 0.8050 - mse: 1.1069 - r2_score: -0.0540\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - loss: 1.0895 - mae: 0.7922 - mse: 1.0895 - r2_score: -0.0540\n",
      "Epoch 8/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 1.0834 - mae: 0.7811 - mse: 1.0834 - r2_score: -0.0430\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step - loss: 1.0682 - mae: 0.7765 - mse: 1.0682 - r2_score: -0.0430\n",
      "Epoch 9/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 1.0385 - mae: 0.7804 - mse: 1.0385 - r2_score: -0.0342\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 1.0398 - mae: 0.7742 - mse: 1.0398 - r2_score: -0.0342\n",
      "Epoch 10/10\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - loss: 0.9886 - mae: 0.7564 - mse: 0.9886 - r2_score: -0.0300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step - loss: 1.0117 - mae: 0.7603 - mse: 1.0117 - r2_score: -0.0300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26b94b9f260>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "METRICS_REGRESSION = [metrics.MeanAbsoluteError(name='mae'), metrics.MeanSquaredError(name='mse')]\n",
    "class R2Callback(keras.callbacks.Callback):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.x, self.y = data\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.x, verbose=0)\n",
    "        r2 = sklearn.metrics.r2_score(self.y, y_pred)\n",
    "        logs = logs or {}\n",
    "        logs['r2_score'] = r2\n",
    "        print(f\" - r2_score: {r2:.4f}\")\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=1e-4)\n",
    "interactionModel.compile(optimizer=opt, loss='mse', metrics=METRICS_REGRESSION)\n",
    "cb = [keras.callbacks.EarlyStopping(monitor='loss', patience=30, restore_best_weights=True), R2Callback((X_train, y_train))]\n",
    "interactionModel.fit(X_train, y_train, batch_size=256, epochs=10, callbacks=cb, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ddf311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Scott.Coffin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'block_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Scott.Coffin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'block_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer 'block_10' with a weight list of length 14, but the layer was expecting 0 weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m new_transformer_block.build(model_feature.output_shape)\n\u001b[32m      4\u001b[39m new_transformer_block2.build(model_feature.output_shape)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mnew_transformer_block\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_block1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m new_transformer_block2.set_weights(transformer_block2.get_weights())\n\u001b[32m      7\u001b[39m model_feature.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Scott.Coffin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:731\u001b[39m, in \u001b[36mLayer.set_weights\u001b[39m\u001b[34m(self, weights)\u001b[39m\n\u001b[32m    729\u001b[39m layer_weights = \u001b[38;5;28mself\u001b[39m.weights\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_weights) != \u001b[38;5;28mlen\u001b[39m(weights):\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    732\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou called `set_weights(weights)` on layer \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith a weight list of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the layer \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwas expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    735\u001b[39m     )\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m variable, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(layer_weights, weights):\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m variable.shape != value.shape:\n",
      "\u001b[31mValueError\u001b[39m: You called `set_weights(weights)` on layer 'block_10' with a weight list of length 14, but the layer was expecting 0 weights."
     ]
    }
   ],
   "source": [
    "\n",
    "new_transformer_block = Block(dim)\n",
    "new_transformer_block2 = Block(dim)\n",
    "new_transformer_block.build(model_feature.output_shape)\n",
    "new_transformer_block2.build(model_feature.output_shape)\n",
    "new_transformer_block.set_weights(transformer_block1.get_weights())\n",
    "new_transformer_block2.set_weights(transformer_block2.get_weights())\n",
    "model_feature.trainable = False\n",
    "new_transformer_block.trainable = False\n",
    "new_transformer_block2.trainable = False\n",
    "input_final = Input(shape=(MAX_SMI_LEN, NUM_CHARS))\n",
    "feat_out = model_feature(input_final)\n",
    "tr1 = new_transformer_block(feat_out)\n",
    "tr1 = Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(tr1)\n",
    "tr2 = new_transformer_block2(feat_out)\n",
    "tr2 = Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(tr2)\n",
    "concat = Concatenate(axis=-1)([tr1, tr2])\n",
    "pooled_f = GlobalAveragePooling1D()(concat)\n",
    "fc1 = Dense(512, activation='relu')(pooled_f)\n",
    "fc1 = BatchNormalization()(fc1)\n",
    "fc1 = Dropout(0.1)(fc1)\n",
    "fc2 = Dense(256, activation='relu')(fc1)\n",
    "fc2 = BatchNormalization()(fc2)\n",
    "fc2 = Dropout(0.1)(fc2)\n",
    "fc3 = Dense(64, activation='relu')(fc2)\n",
    "output = Dense(1)(fc3)\n",
    "model_final = keras.Model(inputs=input_final, outputs=output, name='regression_model')\n",
    "model_final.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0513ed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m opt_final = optimizers.Adam(learning_rate=\u001b[32m1e-4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel_final\u001b[49m.compile(optimizer=opt_final, loss=\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m, metrics=METRICS_REGRESSION)\n\u001b[32m      3\u001b[39m cb_final = [keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m30\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m), R2Callback((X_train, y_train))]\n\u001b[32m      4\u001b[39m model_final.fit(X_train, y_train, batch_size=\u001b[32m256\u001b[39m, epochs=\u001b[32m10\u001b[39m, callbacks=cb_final, verbose=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_final' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_final = optimizers.Adam(learning_rate=1e-4)\n",
    "model_final.compile(optimizer=opt_final, loss='mse', metrics=METRICS_REGRESSION)\n",
    "cb_final = [keras.callbacks.EarlyStopping(monitor='loss', patience=30, restore_best_weights=True), R2Callback((X_train, y_train))]\n",
    "model_final.fit(X_train, y_train, batch_size=256, epochs=10, callbacks=cb_final, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f87047cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     r2 = sklearn.metrics.r2_score(y_orig, y_pred)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mae, mse, r2\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_metrics = evaluate(\u001b[43mmodel_final\u001b[49m, X_train, y_train, scaler_y.inverse_transform(y_train))\n\u001b[32m     10\u001b[39m test_metrics = evaluate(model_final, X_test, y_test, scaler_y.inverse_transform(y_test))\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain MAE, MSE, R2:\u001b[39m\u001b[33m\"\u001b[39m, train_metrics)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_final' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(model, X, y_scaled, y_orig):\n",
    "    y_pred_scaled = model.predict(X)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    mae = sklearn.metrics.mean_absolute_error(y_orig, y_pred)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_orig, y_pred)\n",
    "    r2 = sklearn.metrics.r2_score(y_orig, y_pred)\n",
    "    return mae, mse, r2\n",
    "\n",
    "train_metrics = evaluate(model_final, X_train, y_train, scaler_y.inverse_transform(y_train))\n",
    "test_metrics = evaluate(model_final, X_test, y_test, scaler_y.inverse_transform(y_test))\n",
    "print(\"Train MAE, MSE, R2:\", train_metrics)\n",
    "print(\"Test MAE, MSE, R2:\", test_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
