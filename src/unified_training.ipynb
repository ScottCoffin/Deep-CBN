{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f436bfff",
   "metadata": {},
   "source": [
    "# Unified Deep-CBN Training\n",
    "This notebook provides a unified training function capable of handling both classification and regression tasks using the Deep-CBN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40fbe0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438d040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character dictionary used to encode SMILES strings\n",
    "# Dictionary for converting SMILES characters to numbers\n",
    "smiles_dict = {\n",
    "    \"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2,\n",
    "    \"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6,\n",
    "    \"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43,\n",
    "    \"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13,\n",
    "    \"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51,\n",
    "    \"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56,\n",
    "    \"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60,\n",
    "    \"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64,\n",
    "    \" \": 65, \":\": 66, \",\": 67, \"p\": 68, \"j\": 69, \"*\": 70\n",
    "}\n",
    "\n",
    "MAX_SMI_LEN = 100\n",
    "NUM_CHARS = 71\n",
    "\n",
    "def label_smiles(line):\n",
    "    X = np.zeros(MAX_SMI_LEN, dtype=int)\n",
    "    for i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "        if ch in smiles_dict:\n",
    "            X[i] = smiles_dict[ch]\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e417fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(mode):\n",
    "    inp = layers.Input(shape=(MAX_SMI_LEN, NUM_CHARS), name='XDinput')\n",
    "    x = layers.Conv1D(64, 2, activation='relu')(inp)\n",
    "    x = layers.Conv1D(64, 4, activation='relu')(x)\n",
    "    x = layers.Conv1D(128, 4, activation='relu')(x)\n",
    "    feature_output = x\n",
    "    feature_model = models.Model(inp, feature_output, name='model_feature')\n",
    "\n",
    "    pred_inp = layers.Input(shape=(feature_output.shape[1], feature_output.shape[2]))\n",
    "    y = layers.GlobalAveragePooling1D()(pred_inp)\n",
    "    y = layers.Dense(512, activation='relu')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.1)(y)\n",
    "    y = layers.Dense(256, activation='relu')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.1)(y)\n",
    "    y = layers.Dense(64, activation='relu')(y)\n",
    "    if mode == 'classification':\n",
    "        outputs = layers.Dense(2, activation='softmax')(y)\n",
    "    else:\n",
    "        outputs = layers.Dense(1)(y)\n",
    "    pred_model = models.Model(pred_inp, outputs, name='model_pred')\n",
    "\n",
    "    inter_out = pred_model(feature_output)\n",
    "    interaction_model = models.Model(inp, inter_out, name='interactionModel')\n",
    "    return feature_model, pred_model, interaction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69962b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_cbn(df, target_col, mode='classification', epochs=10, smiles_col='smiles'):\n",
    "    smiles = df[smiles_col].astype(str)\n",
    "    y = df[target_col]\n",
    "    X = np.array([label_smiles(s) for s in smiles])\n",
    "    X = to_categorical(X, num_classes=NUM_CHARS)\n",
    "\n",
    "    if mode == 'classification':\n",
    "        y_data = to_categorical(y.values, num_classes=2)\n",
    "    else:\n",
    "        y_data = y.values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_data, test_size=0.2, random_state=42,\n",
    "        stratify=y if mode=='classification' else None)\n",
    "\n",
    "    feat_model, pred_model, inter_model = build_models(mode)\n",
    "\n",
    "    if mode == 'classification':\n",
    "        loss = 'categorical_crossentropy'\n",
    "        METRICS = [\n",
    "            metrics.CategoricalAccuracy(name='accuracy'),\n",
    "            metrics.Precision(name='precision'),\n",
    "            metrics.Recall(name='recall'),\n",
    "            metrics.AUC(name='auc'),\n",
    "            metrics.F1Score(average='macro', name='f1_score')\n",
    "        ]\n",
    "    else:\n",
    "        def r2_score(y_true, y_pred):\n",
    "            ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "            ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "            return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n",
    "        loss = 'mse'\n",
    "        METRICS = [metrics.MeanAbsoluteError(name='mae'), metrics.MeanSquaredError(name='mse'), r2_score]\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "    inter_model.compile(optimizer=optimizers.Adam(1e-3), loss=loss, metrics=METRICS)\n",
    "    inter_model.fit(X_train, y_train, epochs=epochs, batch_size=256, callbacks=[es], verbose=0)\n",
    "    phase1_test = inter_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    feature_train = feat_model.predict(X_train)\n",
    "    feature_test = feat_model.predict(X_test)\n",
    "\n",
    "    model_phaz2 = models.clone_model(pred_model)\n",
    "    model_phaz2.compile(optimizer=optimizers.Adam(1e-3), loss=loss, metrics=METRICS)\n",
    "    model_phaz2.fit(feature_train, y_train, epochs=epochs, batch_size=256, callbacks=[es], verbose=0)\n",
    "\n",
    "    inputs = feat_model.input\n",
    "    outputs = pred_model(feat_model.output)\n",
    "    model_phaz3 = models.Model(inputs, outputs, name='model_phase3')\n",
    "    model_phaz3.compile(optimizer=optimizers.Adam(1e-4), loss=loss, metrics=METRICS)\n",
    "    model_phaz3.fit(X_train, y_train, epochs=epochs, batch_size=256, callbacks=[es], verbose=0)\n",
    "    train_eval = model_phaz3.evaluate(X_train, y_train, verbose=0)\n",
    "    test_eval = model_phaz3.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    results = {\n",
    "        'phase1_test': phase1_test,\n",
    "        'phase3_train': train_eval,\n",
    "        'phase3_test': test_eval\n",
    "    }\n",
    "    return model_phaz3, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c895a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example usage on multiple targets\n",
    "data = pd.read_csv('../Data/tox21.csv')\n",
    "targets = ['NR-AR', 'NR-ER', 'NR-PPAR-gamma']\n",
    "summary = {}\n",
    "for tgt in targets:\n",
    "    df = data[[tgt, 'smiles']].dropna()\n",
    "    model, metrics_dict = train_deep_cbn(df, tgt, mode='classification', epochs=5)\n",
    "    summary[tgt] = metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a505e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phase1_loss</th>\n",
       "      <th>phase3_test_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.308201</td>\n",
       "      <td>0.977601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.539536</td>\n",
       "      <td>0.903288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.344456</td>\n",
       "      <td>0.981145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target  phase1_loss  phase3_test_metric\n",
       "0          NR-AR     0.308201            0.977601\n",
       "1          NR-ER     0.539536            0.903288\n",
       "2  NR-PPAR-gamma     0.344456            0.981145"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize performance metrics\n",
    "summary_rows = []\n",
    "for target, met in summary.items():\n",
    "    row = {'target': target}\n",
    "    row.update({\n",
    "        'phase1_loss': met['phase1_test'][0],\n",
    "        'phase3_test_metric': met['phase3_test'][4] if len(met['phase3_test'])>4 else met['phase3_test'][2]\n",
    "    })\n",
    "    summary_rows.append(row)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
