{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f436bfff",
   "metadata": {},
   "source": [
    "# Unified Deep-CBN Training\n",
    "This notebook provides a unified training function capable of handling both classification and regression tasks using the Deep-CBN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbe0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character dictionary used to encode SMILES strings\n",
    "smiles_dict = {\n",
    "    '#': 29, '%': 30, ')': 31, '(': 1, '+': 32, '-': 33, '/': 34, '.': 2,\n",
    "    '1': 35, '0': 3, '3': 36, '2': 4, '5': 37, '4': 5, '7': 38, '6': 6,\n",
    "    '9': 39, '8': 7, '=': 40, 'A': 41, '@': 8, 'C': 42, 'B': 9, 'E': 43,\n",
    "    'D': 10, 'G': 44, 'F': 11, 'I': 45, 'H': 12, 'K': 46, 'M': 47, 'L': 13,\n",
    "    'O': 48, 'N': 14, 'P': 15, 'S': 49, 'R': 16, 'U': 50, 'T': 17, 'W': 51,\n",
    "    'V': 18, 'Y': 52, '[': 53, 'Z': 19, ']': 54, '\\': 20, 'a': 55, 'c': 56,\n",
    "    'b': 21, 'e': 57, 'd': 22, 'g': 58, 'f': 23, 'i': 59, 'h': 24, 'm': 60,\n",
    "    'l': 25, 'o': 61, 'n': 26, 's': 62, 'r': 27, 'u': 63, 't': 28, 'y': 64,\n",
    "    ' ': 65, ':': 66, ',': 67, 'p': 68, 'j': 69, '*': 70\n",
    "}\n",
    "MAX_SMI_LEN = 100\n",
    "NUM_CHARS = 71\n",
    "\n",
    "def label_smiles(line):\n",
    "    X = np.zeros(MAX_SMI_LEN, dtype=int)\n",
    "    for i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "        if ch in smiles_dict:\n",
    "            X[i] = smiles_dict[ch]\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(mode):\n",
    "    inp = layers.Input(shape=(MAX_SMI_LEN, NUM_CHARS), name='XDinput')\n",
    "    x = layers.Conv1D(64, 2, activation='relu')(inp)\n",
    "    x = layers.Conv1D(64, 4, activation='relu')(x)\n",
    "    x = layers.Conv1D(128, 4, activation='relu')(x)\n",
    "    feature_output = x\n",
    "    feature_model = models.Model(inp, feature_output, name='model_feature')\n",
    "\n",
    "    pred_inp = layers.Input(shape=(feature_output.shape[1], feature_output.shape[2]))\n",
    "    y = layers.GlobalAveragePooling1D()(pred_inp)\n",
    "    y = layers.Dense(512, activation='relu')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.1)(y)\n",
    "    y = layers.Dense(256, activation='relu')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.1)(y)\n",
    "    y = layers.Dense(64, activation='relu')(y)\n",
    "    if mode == 'classification':\n",
    "        outputs = layers.Dense(2, activation='softmax')(y)\n",
    "    else:\n",
    "        outputs = layers.Dense(1)(y)\n",
    "    pred_model = models.Model(pred_inp, outputs, name='model_pred')\n",
    "\n",
    "    inter_out = pred_model(feature_output)\n",
    "    interaction_model = models.Model(inp, inter_out, name='interactionModel')\n",
    "    return feature_model, pred_model, interaction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69962b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_cbn(df, target_col, mode='classification', epochs=10, smiles_col='smiles'):\n",
    "    smiles = df[smiles_col].astype(str)\n",
    "    y = df[target_col]\n",
    "    X = np.array([label_smiles(s) for s in smiles])\n",
    "    X = to_categorical(X, num_classes=NUM_CHARS)\n",
    "\n",
    "    if mode == 'classification':\n",
    "        y_data = to_categorical(y.values, num_classes=2)\n",
    "    else:\n",
    "        y_data = y.values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_data, test_size=0.2, random_state=42,\n",
    "        stratify=y if mode=='classification' else None)\n",
    "\n",
    "    feat_model, pred_model, inter_model = build_models(mode)\n",
    "\n",
    "    if mode == 'classification':\n",
    "        loss = 'categorical_crossentropy'\n",
    "        METRICS = [\n",
    "            metrics.CategoricalAccuracy(name='accuracy'),\n",
    "            metrics.Precision(name='precision'),\n",
    "            metrics.Recall(name='recall'),\n",
    "            metrics.AUC(name='auc'),\n",
    "            metrics.F1Score(average='macro', name='f1_score')\n",
    "        ]\n",
    "    else:\n",
    "        def r2_score(y_true, y_pred):\n",
    "            ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "            ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "            return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n",
    "        loss = 'mse'\n",
    "        METRICS = [metrics.MeanAbsoluteError(name='mae'), metrics.MeanSquaredError(name='mse'), r2_score]\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "    inter_model.compile(optimizer=optimizers.Adam(1e-3), loss=loss, metrics=METRICS)\n",
    "    inter_model.fit(X_train, y_train, epochs=epochs, batch_size=256, callbacks=[es], verbose=0)\n",
    "    phase1_test = inter_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    feature_train = feat_model.predict(X_train)\n",
    "    feature_test = feat_model.predict(X_test)\n",
    "\n",
    "    model_phaz2 = models.clone_model(pred_model)\n",
    "    model_phaz2.compile(optimizer=optimizers.Adam(1e-3), loss=loss, metrics=METRICS)\n",
    "    model_phaz2.fit(feature_train, y_train, epochs=epochs, batch_size=256, callbacks=[es], verbose=0)\n",
    "\n",
    "    inputs = feat_model.input\n",
    "    outputs = pred_model(feat_model.output)\n",
    "    model_phaz3 = models.Model(inputs, outputs, name='model_phase3')\n",
    "    model_phaz3.compile(optimizer=optimizers.Adam(1e-4), loss=loss, metrics=METRICS)\n",
    "    model_phaz3.fit(X_train, y_train, epochs=epochs, batch_size=256, callbacks=[es], verbose=0)\n",
    "    train_eval = model_phaz3.evaluate(X_train, y_train, verbose=0)\n",
    "    test_eval = model_phaz3.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    results = {\n",
    "        'phase1_test': phase1_test,\n",
    "        'phase3_train': train_eval,\n",
    "        'phase3_test': test_eval\n",
    "    }\n",
    "    return model_phaz3, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage on multiple targets\n",
    "data = pd.read_csv('../Data/tox21.csv')\n",
    "targets = ['NR-AR', 'NR-ER', 'NR-PPAR-gamma']\n",
    "summary = {}\n",
    "for tgt in targets:\n",
    "    df = data[[tgt, 'smiles']].dropna()\n",
    "    model, metrics_dict = train_deep_cbn(df, tgt, mode='classification', epochs=5)\n",
    "    summary[tgt] = metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a505e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize performance metrics\n",
    "summary_rows = []\n",
    "for target, met in summary.items():\n",
    "    row = {'target': target}\n",
    "    row.update({\n",
    "        'phase1_loss': met['phase1_test'][0],\n",
    "        'phase3_test_metric': met['phase3_test'][4] if len(met['phase3_test'])>4 else met['phase3_test'][2]\n",
    "    })\n",
    "    summary_rows.append(row)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
