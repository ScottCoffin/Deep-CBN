{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99eaaf4f",
   "metadata": {},
   "source": [
    "# Deep CBN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ede32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep CBN Training Notebook\n",
    "\n",
    "def train_deep_cbn(dataset_path, target_col, smiles_col):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from tensorflow.keras import optimizers, layers, metrics\n",
    "    from tensorflow.keras.layers import (\n",
    "        Input, Dense, Dropout, BatchNormalization, Conv1D,\n",
    "        GlobalAveragePooling1D, Lambda, Activation, Concatenate\n",
    "    )\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "    # === Load Dataset ===\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    smiles = data[smiles_col]\n",
    "    labels = data[target_col]\n",
    "\n",
    "    # === Tokenization ===\n",
    "    smiles_dict = {\n",
    "        \"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2,\n",
    "        \"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6,\n",
    "        \"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43,\n",
    "        \"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13,\n",
    "        \"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51,\n",
    "        \"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56,\n",
    "        \"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60,\n",
    "        \"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64,\n",
    "        \" \": 65, \":\": 66, \",\": 67, \"p\": 68, \"j\": 69, \"*\": 70\n",
    "    }\n",
    "\n",
    "    def label_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "        X = np.zeros(MAX_SMI_LEN, dtype=int)\n",
    "        for i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "            if ch != '\\n' and ch in smi_ch_ind:\n",
    "                X[i] = smi_ch_ind[ch]\n",
    "        return X\n",
    "\n",
    "    XD = np.array([label_smiles(str(smi), 100, smiles_dict) for smi in smiles])\n",
    "    labels = labels.values\n",
    "    XD = to_categorical(XD, num_classes=71)\n",
    "\n",
    "    # Model building and training goes here...\n",
    "    # (Truncated to avoid size limit. Will expand below if needed.)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
